{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPzEAmnhYA0XvLm/bF+sRIW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/leilafarsani/NLP-go-get/blob/main/NLP01.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# NLP Workshop (Session 1)\n",
        "\n",
        "Learning and implementing Natural Language Processing (NLP) techniques with Python's NLTK and spaCy libraries."
      ],
      "metadata": {
        "id": "BkEqKrBboUld"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. NLP Toolkit\n",
        "\n",
        "Two fundamental libraries for natural language processing:\n",
        "\n",
        "### NLTK (Natural Language Toolkit)\n",
        "- **Purpose**: Open-source Python library designed for educational and research applications\n",
        "- **Features**: Comprehensive tools for tokenization, stemming, lemmatization, parsing, and more\n",
        "- **Resources**: Includes extensive corpora and lexical resources\n",
        "- **Documentation**: [NLTK Website](https://www.nltk.org/) | [Wikipedia](https://en.wikipedia.org/wiki/Natural_Language_Toolkit)\n",
        "\n",
        "### spaCy\n",
        "- **Purpose**: Industrial-strength NLP library optimized for real-world applications\n",
        "- **Features**: Fast and accurate processing for tokenization, named entity recognition, and dependency parsing\n",
        "- **Strengths**: Modern API with efficient design for large-scale text processing\n",
        "- **Documentation**: [spaCy Website](https://spacy.io/) | [Wikipedia](https://en.wikipedia.org/wiki/SpaCy)"
      ],
      "metadata": {
        "id": "Nyd2WYADoQqE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Library Setup\n",
        "\n",
        "### NLTK Installation and Resource Downloads\n",
        "- Installs the NLTK library and imports it\n",
        "- Downloads essential NLTK resources:\n",
        "  - `punkt`: Tokenizer for splitting text into sentences and words\n",
        "  - `punkt_tab`: Tab-delimited version of punkt tokenizer models\n",
        "  - `stopwords`: Common words often filtered out in NLP tasks\n",
        "  - `wordnet`: Lexical database for word relationships\n",
        "  - `gutenberg`: Corpus of classic literature texts\n",
        "  - `averaged_perceptron_tagger_eng`: For part-of-speech tagging\n",
        "\n",
        "### spaCy Installation and Model Setup\n",
        "- Installs the spaCy library and imports it\n",
        "- Downloads the small English language model (`en_core_web_sm`)\n",
        "- Creates the spaCy NLP pipeline with `nlp = spacy.load(\"en_core_web_sm\")`"
      ],
      "metadata": {
        "id": "mq-Kv6aKt3iu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- NLTK Setup ---\n",
        "!pip install nltk\n",
        "import nltk\n",
        "# Download essential NLTK datasets: tokenizers, stopwords, WordNet, etc.\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('gutenberg')\n",
        "nltk.download('averaged_perceptron_tagger_eng')\n",
        "\n",
        "# --- spaCy Setup ---\n",
        "!pip install spacy\n",
        "import spacy\n",
        "\n",
        "# Download and load the small English model for spaCy\n",
        "!python -m spacy download en_core_web_sm\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n"
      ],
      "metadata": {
        "id": "cg1p5V0Gusmg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}